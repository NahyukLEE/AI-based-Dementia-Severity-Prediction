{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "coral-collective",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "import torchvision.transforms as tr\n",
    "import torchvision.datasets as dset\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.autograd import Function\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "\n",
    "import visdom\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "illegal-breed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n",
      "Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "## terminal command : python -m visdom.server\n",
    "vis = visdom.Visdom()\n",
    "vis2 = visdom.Visdom()\n",
    "plot = vis.line(Y=torch.tensor([0]), X=torch.tensor([0]))\n",
    "plot2= vis2.line(Y=torch.tensor([0]),X=torch.tensor([0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "consecutive-athletics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "great-russia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 666\n",
      "    Root location: ./CNN\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=(128, 128), interpolation=PIL.Image.BILINEAR)\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "transf = tr.Compose([tr.Resize((128, 128)),\n",
    "                     tr.ToTensor(),\n",
    "                     tr.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) # 128x128 이미지 크기 변환 후 텐서 제작\n",
    "image_datasets = torchvision.datasets.ImageFolder(root='./CNN', transform=transf) # 4번 검사 데이터 데이터 로딩\n",
    "print(image_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "working-executive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Deform&PSV', 'Deformed', 'Normal', 'PSV']\n"
     ]
    }
   ],
   "source": [
    "class_names = image_datasets.classes\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "loaded-ethnic",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.6 * len(image_datasets))\n",
    "test_size = len(image_datasets) - train_size\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(image_datasets, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = 8, shuffle = True)\n",
    "validation_loader = DataLoader(test_dataset, batch_size = 8, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "unknown-restoration",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    #Imshow for Tensor#\n",
    "    inp = inp.numpy().transpose((1,2,0))\n",
    "    mean = np.array([0.5, 0.5, 0.5])\n",
    "    std = np.array([0.5, 0.5, 0.5])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp,0,1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001) # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "palestinian-services",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 2, 2, 2, 0, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "inputs, classes = next(iter(train_loader))\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "helpful-grade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "out = torchvision.utils.make_grid(inputs)\n",
    "imshow(out,title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "instant-elevation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to C:\\Users\\user/.cache\\torch\\hub\\checkpoints\\resnet50-19c8e357.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e97114193b4e4683a26bac82ddd50ef5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = torchvision.models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "running-tribute",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "metropolitan-google",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ftrs = model.fc.in_features # fc의 입력 노드 수를 산출한다. 512개\n",
    "model.fc = nn.Linear(num_ftrs, 4) # fc를 nn.Linear(num_ftrs, 10)로 대체한다.\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "starting-carry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실함수, 최적화 함수 정의\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "northern-rabbit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Train loss: 0.702 | Train accuracy: 77.94%\n",
      "[2] Train loss: 0.343 | Train accuracy: 85.96%\n",
      "[3] Train loss: 0.231 | Train accuracy: 91.48%\n",
      "[4] Train loss: 0.219 | Train accuracy: 91.73%\n",
      "[5] Train loss: 0.114 | Train accuracy: 95.99%\n",
      "[6] Train loss: 0.138 | Train accuracy: 95.24%\n",
      "[7] Train loss: 0.116 | Train accuracy: 95.74%\n",
      "[8] Train loss: 0.137 | Train accuracy: 95.49%\n",
      "[9] Train loss: 0.142 | Train accuracy: 93.48%\n",
      "[10] Train loss: 0.169 | Train accuracy: 94.24%\n",
      "[11] Train loss: 0.081 | Train accuracy: 96.24%\n",
      "[12] Train loss: 0.077 | Train accuracy: 97.74%\n",
      "[13] Train loss: 0.077 | Train accuracy: 97.74%\n",
      "[14] Train loss: 0.050 | Train accuracy: 98.25%\n",
      "[15] Train loss: 0.095 | Train accuracy: 96.74%\n",
      "[16] Train loss: 0.032 | Train accuracy: 99.00%\n",
      "[17] Train loss: 0.061 | Train accuracy: 97.49%\n",
      "[18] Train loss: 0.105 | Train accuracy: 96.99%\n",
      "[19] Train loss: 0.118 | Train accuracy: 95.74%\n",
      "[20] Train loss: 0.115 | Train accuracy: 96.99%\n",
      "[21] Train loss: 0.117 | Train accuracy: 96.24%\n",
      "[22] Train loss: 0.069 | Train accuracy: 97.99%\n",
      "[23] Train loss: 0.166 | Train accuracy: 94.74%\n",
      "[24] Train loss: 0.170 | Train accuracy: 93.73%\n",
      "[25] Train loss: 0.056 | Train accuracy: 97.99%\n",
      "[26] Train loss: 0.045 | Train accuracy: 98.75%\n",
      "[27] Train loss: 0.043 | Train accuracy: 98.75%\n",
      "[28] Train loss: 0.020 | Train accuracy: 99.50%\n",
      "[29] Train loss: 0.005 | Train accuracy: 100.00%\n",
      "[30] Train loss: 0.005 | Train accuracy: 100.00%\n",
      "[31] Train loss: 0.006 | Train accuracy: 100.00%\n",
      "[32] Train loss: 0.008 | Train accuracy: 99.75%\n",
      "[33] Train loss: 0.003 | Train accuracy: 100.00%\n",
      "[34] Train loss: 0.003 | Train accuracy: 100.00%\n",
      "[35] Train loss: 0.005 | Train accuracy: 100.00%\n",
      "[36] Train loss: 0.003 | Train accuracy: 100.00%\n",
      "[37] Train loss: 0.004 | Train accuracy: 100.00%\n",
      "[38] Train loss: 0.030 | Train accuracy: 99.50%\n",
      "[39] Train loss: 0.165 | Train accuracy: 94.24%\n",
      "[40] Train loss: 0.239 | Train accuracy: 90.48%\n",
      "[41] Train loss: 0.210 | Train accuracy: 92.73%\n",
      "[42] Train loss: 0.131 | Train accuracy: 95.49%\n",
      "[43] Train loss: 0.088 | Train accuracy: 96.99%\n",
      "[44] Train loss: 0.077 | Train accuracy: 96.99%\n",
      "[45] Train loss: 0.058 | Train accuracy: 98.50%\n",
      "[46] Train loss: 0.205 | Train accuracy: 93.23%\n",
      "[47] Train loss: 0.275 | Train accuracy: 92.73%\n",
      "[48] Train loss: 0.090 | Train accuracy: 97.49%\n",
      "[49] Train loss: 0.055 | Train accuracy: 98.75%\n",
      "[50] Train loss: 0.125 | Train accuracy: 95.24%\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(50):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    for data in train_loader:\n",
    "        \n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        pred = outputs.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "\n",
    "    cost = running_loss / len(train_loader)\n",
    "    \n",
    "    print('[%d] Train loss: %.3f | Train accuracy: %.2f%%' %(epoch + 1, cost, 100.*correct/len(train_loader.dataset))) \n",
    "    \n",
    "    #test loss 값을 Y축, 전달받은 파라미터 epoch를 X 값으로 \n",
    "    vis.line(Y=[cost], X=np.array([epoch]),win=plot,update='append')\n",
    "\n",
    "    # accuracy를 구하는 수식을 Y값으로 epoch를 X값으로 \n",
    "    vis2.line(Y=[100.*correct/len(train_loader.dataset)], X=np.array([epoch]),win=plot2,update='append')\n",
    "    \n",
    "torch.save(model.state_dict(), './models/test4_resnet50_pretrained.pth')      \n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "first-optimum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torchvision.models.resnet50(pretrained=False)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 4) \n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load('./models/test4_resnet50_pretrained.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "historic-thing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 84.27 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in validation_loader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('Accuracy of the network on the test images: %.2f %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "mounted-lawrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet50(pretrained=False)\n",
    "num_ftrs = model.fc.in_features # fc의 입력 노드 수를 산출한다. 512개\n",
    "model.fc = nn.Linear(num_ftrs, 4) # fc를 nn.Linear(num_ftrs, 10)로 대체한다.\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "interstate-button",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실함수, 최적화 함수 정의\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "expanded-suspension",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Train loss: 0.736 | Train accuracy: 78.20%\n",
      "[2] Train loss: 0.628 | Train accuracy: 80.70%\n",
      "[3] Train loss: 0.590 | Train accuracy: 82.71%\n",
      "[4] Train loss: 0.555 | Train accuracy: 82.46%\n",
      "[5] Train loss: 0.445 | Train accuracy: 85.46%\n",
      "[6] Train loss: 0.486 | Train accuracy: 83.71%\n",
      "[7] Train loss: 0.451 | Train accuracy: 83.71%\n",
      "[8] Train loss: 0.287 | Train accuracy: 89.97%\n",
      "[9] Train loss: 0.339 | Train accuracy: 87.72%\n",
      "[10] Train loss: 0.307 | Train accuracy: 89.72%\n",
      "[11] Train loss: 0.344 | Train accuracy: 87.22%\n",
      "[12] Train loss: 0.388 | Train accuracy: 87.22%\n",
      "[13] Train loss: 0.196 | Train accuracy: 93.23%\n",
      "[14] Train loss: 0.178 | Train accuracy: 94.99%\n",
      "[15] Train loss: 0.174 | Train accuracy: 93.73%\n",
      "[16] Train loss: 0.134 | Train accuracy: 95.49%\n",
      "[17] Train loss: 0.099 | Train accuracy: 97.49%\n",
      "[18] Train loss: 0.054 | Train accuracy: 98.25%\n",
      "[19] Train loss: 0.075 | Train accuracy: 97.99%\n",
      "[20] Train loss: 0.210 | Train accuracy: 92.73%\n",
      "[21] Train loss: 0.160 | Train accuracy: 94.49%\n",
      "[22] Train loss: 0.119 | Train accuracy: 95.74%\n",
      "[23] Train loss: 0.222 | Train accuracy: 93.23%\n",
      "[24] Train loss: 0.120 | Train accuracy: 96.49%\n",
      "[25] Train loss: 0.077 | Train accuracy: 97.49%\n",
      "[26] Train loss: 0.092 | Train accuracy: 96.99%\n",
      "[27] Train loss: 0.116 | Train accuracy: 95.74%\n",
      "[28] Train loss: 0.052 | Train accuracy: 98.75%\n",
      "[29] Train loss: 0.028 | Train accuracy: 99.00%\n",
      "[30] Train loss: 0.041 | Train accuracy: 97.99%\n",
      "[31] Train loss: 0.042 | Train accuracy: 98.75%\n",
      "[32] Train loss: 0.059 | Train accuracy: 97.99%\n",
      "[33] Train loss: 0.123 | Train accuracy: 96.74%\n",
      "[34] Train loss: 0.093 | Train accuracy: 97.24%\n",
      "[35] Train loss: 0.082 | Train accuracy: 96.49%\n",
      "[36] Train loss: 0.149 | Train accuracy: 94.74%\n",
      "[37] Train loss: 0.074 | Train accuracy: 97.49%\n",
      "[38] Train loss: 0.051 | Train accuracy: 98.25%\n",
      "[39] Train loss: 0.044 | Train accuracy: 97.99%\n",
      "[40] Train loss: 0.038 | Train accuracy: 98.75%\n",
      "[41] Train loss: 0.017 | Train accuracy: 99.50%\n",
      "[42] Train loss: 0.006 | Train accuracy: 100.00%\n",
      "[43] Train loss: 0.002 | Train accuracy: 100.00%\n",
      "[44] Train loss: 0.001 | Train accuracy: 100.00%\n",
      "[45] Train loss: 0.001 | Train accuracy: 100.00%\n",
      "[46] Train loss: 0.000 | Train accuracy: 100.00%\n",
      "[47] Train loss: 0.000 | Train accuracy: 100.00%\n",
      "[48] Train loss: 0.000 | Train accuracy: 100.00%\n",
      "[49] Train loss: 0.001 | Train accuracy: 100.00%\n",
      "[50] Train loss: 0.000 | Train accuracy: 100.00%\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(50):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    for data in train_loader:\n",
    "        \n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        pred = outputs.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "\n",
    "    cost = running_loss / len(train_loader)\n",
    "    \n",
    "    print('[%d] Train loss: %.3f | Train accuracy: %.2f%%' %(epoch + 1, cost, 100.*correct/len(train_loader.dataset))) \n",
    "    \n",
    "    #test loss 값을 Y축, 전달받은 파라미터 epoch를 X 값으로 \n",
    "    vis.line(Y=[cost], X=np.array([epoch]),win=plot,update='append')\n",
    "\n",
    "    # accuracy를 구하는 수식을 Y값으로 epoch를 X값으로 \n",
    "    vis2.line(Y=[100.*correct/len(train_loader.dataset)], X=np.array([epoch]),win=plot2,update='append')\n",
    "    \n",
    "torch.save(model.state_dict(), './models/test4_resnet50.pth')      \n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "particular-heather",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torchvision.models.resnet50(pretrained=False)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 4) \n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load('./models/test4_resnet50.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "future-contribution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 80.52 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    real_array = []\n",
    "    pred_array = []\n",
    "    for data in validation_loader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        real_array.append(labels.tolist())\n",
    "        pred_array.append(predicted.tolist())\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    real_array = sum(real_array, []) #1차원 리스트로\n",
    "    pred_array = sum(pred_array, []) #1차원 리스트로\n",
    "print('Accuracy of the network on the test images: %.2f %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "manufactured-andrew",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215\n",
      "80.52434456928839\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(len(real_array)):\n",
    "    if real_array[i] == pred_array[i]:\n",
    "        count += 1\n",
    "print(count)\n",
    "print(count/len(real_array)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "mechanical-genome",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Deform&PSV       0.20      0.20      0.20        10\n",
      "    Deformed       0.00      0.00      0.00         8\n",
      "      Normal       0.87      0.96      0.92       216\n",
      "         PSV       0.36      0.15      0.21        33\n",
      "\n",
      "    accuracy                           0.81       267\n",
      "   macro avg       0.36      0.33      0.33       267\n",
      "weighted avg       0.76      0.81      0.78       267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(real_array, pred_array, target_names=['Deform&PSV', 'Deformed', 'Normal', 'PSV']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "played-frequency",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
