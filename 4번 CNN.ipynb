{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "conservative-cycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "import torchvision.transforms as tr\n",
    "import torchvision.datasets as dset\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.autograd import Function\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "\n",
    "import visdom\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "pleasant-desert",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n",
      "Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "vis = visdom.Visdom()\n",
    "vis2 = visdom.Visdom()\n",
    "plot = vis.line(Y=torch.tensor([0]), X=torch.tensor([0]))\n",
    "plot2= vis2.line(Y=torch.tensor([0]),X=torch.tensor([0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "falling-attribute",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "original-storm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 666\n",
      "    Root location: ./CNN\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=(128, 128), interpolation=PIL.Image.BILINEAR)\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "transf = tr.Compose([tr.Resize((128, 128)),\n",
    "                     tr.ToTensor(),\n",
    "                     tr.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) # 128x128 이미지 크기 변환 후 텐서 제작\n",
    "image_datasets = torchvision.datasets.ImageFolder(root='./CNN', transform=transf) # 4번 검사 데이터 데이터 로딩\n",
    "print(image_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "minute-diameter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Deform&PSV', 'Deformed', 'Normal', 'PSV']\n"
     ]
    }
   ],
   "source": [
    "class_names = image_datasets.classes\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "mineral-district",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.7 * len(image_datasets))\n",
    "test_size = len(image_datasets) - train_size\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(image_datasets, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = 8, shuffle = True)\n",
    "validation_loader = DataLoader(test_dataset, batch_size = 8, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fifth-inspector",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    #Imshow for Tensor#\n",
    "    inp = inp.numpy().transpose((1,2,0))\n",
    "    mean = np.array([0.5, 0.5, 0.5])\n",
    "    std = np.array([0.5, 0.5, 0.5])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp,0,1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001) # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "civic-slovakia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 3, 2, 2, 3, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "inputs, classes = next(iter(train_loader))\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afraid-workplace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "out = torchvision.utils.make_grid(inputs)\n",
    "imshow(out,title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "spatial-former",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "blond-restriction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "split-blackberry",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ftrs = model.fc.in_features # fc의 입력 노드 수를 산출한다. 512개\n",
    "model.fc = nn.Linear(num_ftrs, 4) # fc를 nn.Linear(num_ftrs, 10)로 대체한다.\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ranging-necessity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "accessible-wrist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실함수, 최적화 함수 정의\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "normal-malawi",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] loss: 0.629\n",
      "[2] loss: 0.309\n",
      "[3] loss: 0.265\n",
      "[4] loss: 0.151\n",
      "[5] loss: 0.094\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    for data in train_loader:\n",
    "        \n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        pred = outputs.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "\n",
    "    cost = running_loss / len(train_loader)        \n",
    "    print('[%d] loss: %.3f' %(epoch + 1, cost))  \n",
    "    \n",
    "    #test loss 값을 Y축, 전달받은 파라미터 epoch를 X 값으로 \n",
    "    vis.line(Y=[cost], X=np.array([epoch]),win=plot,update='append')\n",
    "    \n",
    "    # accuracy를 구하는 수식을 Y값으로 epoch를 X값으로 \n",
    "    vis2.line(Y=[100.*correct/len(validation_loader.dataset)], X=np.array([epoch]),win=plot2,update='append')\n",
    "    \n",
    "torch.save(model.state_dict(), './models/test4_resnet18.pth')      \n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "identical-hypothetical",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torchvision.models.resnet18(pretrained=False)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 4) \n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load('./models/test4_resnet18.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "sexual-medication",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 86 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in validation_loader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-edward",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sitting-finnish",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
